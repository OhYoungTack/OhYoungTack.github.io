## AlexNet(2012)

### Contribution

- ImageNet 대회에서 전년도 대비 약 9% 이상의 성능 향상으로 압도적인 성능으로 1위를 하였다.
- GPU를 사용하여 매우 의미 있는 결과를 얻어 이후 CNN 구조를 설계할 때 GPU를 사용하는 것이 대세가 되었다.
- 현재 classification 모델의 표준인 <CNN-FC> 구조를 제안하였다.
- 성능 향상과 training 시간을 향상시키기 위한 여러가지 기능(ReLU, LRN, Data augmentation, Dropout)을 포함하였습니다.

----
### Architexture
<img src="/images/AlexNet.png" width="500" height="200">  

- 위 그림의 설명과 같이 5 Convolution Layers, 3 Fully-Connected Layers, 1000 ways Softmax로 구성되어있다.
- 당시 GPU의 스펙이 낮아 2개의 GPU를 병렬로 사용하여 학습하였다.(GTX580 3GB사용)

----
### Algorithm
#### ReLU
<img src="/images/ReLU.png" width="300" height="200">

지금은 기본적으로 사용하지만 tanh, sigmoid등을 사용할 시기였을 때, ReLU를 사용함으로써 학습 속도를 개선하였습니다.
ReLU는 0보다 작은 값은 0으로 사용하고, 0보다 큰 값은 해당 값을 그대로 사용하는 방법입니다. 

#### LRN(Local Response Normalization)
ReLU는 무제한의 활성화가 있기때문에 LRN이 필요합니다.
LRN은 output에서 convolution feature map이 나오면 그중에서 일정 부분만 높게 activation되게 해주는 작업입니다. AlexNet에서는 해당 작업을 수행해 주었다. 첨언하자면 지금은 성능상 큰 이점이 없어서 잘 사용하지 않습니다.

#### Regularization
- Data augmentation  
AlexNet에서는 256 *
256의 original Image를 224 * 224의 Smaller Patch로 떠서 하나의 이미지 안에서 데이터를 32 * 32개를 늘릴 수 있고, 좌우 반전까지 하면 그의 *2배를 해주어 총 2048배의 데이터를 늘릴 수 있습니다.

- Dropout  
Dropout은 Network의 일부를 생략하여 다른 Model을 학습한 것과 같은 효과를 얻어 overfitting을 개선하는 방법입니다. AlexNet에서는 test할 때 모든 뉴런을 사용하지만, output에 0.5를 곱해주었다. 이 방법은 처음이자 마지막으로 수행되었다고 합니다.

## ZFNet(2013)
<img src="/images/ZFNet.png" width="500" height="200">

ZFNet의 구조는 AlexNet에서 GPU를 하나만 쓰고 일부 convolution layer의 kernel 사이즈와 stride를 일부 조절해주었다.(layers1의 filter 사이즈를 11 * 11 -> 7 * 7, stride를 4 -> 1로 수정해주었고, 이에 따라 layers2의 stride를 1 -> 2로 수정하였다.)
ZFNet은 CNN을 가시화하여 CNN의 중간 과정을 눈으로 보고 개선 방향을 파악할 수 있는 방법을 만들었다.(Visualizing)

### Visualizing
CNN은 convolution계산 후 활성 함수를 통해 feature map을 생성하고, pooling하여 이미지를 축소 시키는 것을 반복하는데 이 과적을 반대로 해주어 원본 이미지에 mapping할 수 있는 이미지를 생성 할 수 있을 것이다.<img src="/images/ZFNet_1.png" width="250" height="350">

max-pooling은 이미지를 축소 시키는 과정에서 가장 강한 자극을 전달하는데 이 과정을 반대로하면 어느 부분이 강한 자극인지를 알 수 없는 문제가 생긴다. Visualizing은 가장 강한 자극의 위치를 가지고 있도록 하여 이와 같은 문제를 해결하였다.## VGG(2014)
stride는 모두 1, 제로패딩 1, 모든 convolution filter의 크기는 3 * 3 pooling은 2 * 2을 사용해주었다.

간단한 방법론으로 좋은 성적을 얻었다.

## GoogLeNet(2014)
<img src="/images/GoogLeNet.png" width="300" height="200">

Filter concatenation은 filter를 채널방향으로 더한 것을 의미한다. 

(b)그림은 (a)모델의 개선된 모델이다. 채널의 수를 중간에 한 번 줄였을 때 layers가 오히려 하나 더 쓰였는데 이 네트워크를 정의하는 파라미터의 수가 줄어든다. 이는 convolution의 파라미터를 정의하는 것은 input채널과 output채널이기 때문이다.

Receptive field : 출력단에 있는 하나의 픽셀이 입력 이미지의 얼마의 픽셀을 보고 이 정보가 취합되었는지를 의미한다.

Max-Pooling의 경우 1 * 1이 뒤에있는데 이는 출력 채널의 크기를 맞추기 위함이다. 

## ResNet(2015)
<img src="/images/GoogLeNet.png" width="100" height="300">

network가 deep 할 때 학습이 잘되는가를 생각해보면 아니라는 것을 알 수 있다. 이는 Vanishing/exploding gradients때문인데 이는 Better initialization methods/ batch normalization/ ReLU 과 같은 방법으로 해결할 수 있다.

Overfitting는 Training 에러는 줄어들고 Training acc는 늘어나는데 test acc가 계속 떨어질경우를 말한다. ResNet은 트레이닝도 잘되고 테스트도 잘되는데 성능이 잘 안나오는 경우인 Degradation을 해결하려하였다.

### Residual learning building block어떤 타겟과 현재 입력과의 차이만을 학습하게 해주는 방법이다. 입력과 출력의 차원이 같아야 한다는 단점을 갖고있다. 

1 * 1 conv를 이용하여 채널을 줄여주고 3 * 3 conv를 해주고 다시 1 * 1 conv를 해준다. 마지막에 다시 1 * 1 conv를 해주는 이유는 입력과 출력의 채널을 같게 해주어야하기 때문에 추가해준것이다. 만약 3 * 3 conv의 채널을  입력 채널과 같게해주면 바로 더해줄 수는 있어서 마지막의 1 * 1 conv가 필요없지만 파라미터의 수가 많아질 것이다.

ResNet의 한계는 Layers의 개수가 1000개를 넘어가면 여전히 잘 학습이 안되는 성능을 보인다는 것이다.

## Reference

[ImageNet Classification with Deep Convolutional
Neural Networks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)  [ReLU](http://pythonkim.tistory.com/40)  
[LRN](https://translate.google.co.kr/translate?hl=ko&sl=en&u=https://prateekvjoshi.com/2016/04/05/what-is-local-response-normalization-in-convolutional-neural-networks/&prev=search)   
[최신논문으로 시작하는 딥러닝_최성준](http://m.edwith.org/deeplearningchoi)  
[라온피플](https://m.blog.naver.com/PostView.nhn?blogId=laonple&logNo=220654387455&proxyReferer=https%3A%2F%2Fwww.google.co.kr%2F)
