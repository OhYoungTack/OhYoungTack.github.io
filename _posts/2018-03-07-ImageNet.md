## AlexNet(2012)
<img src="/images/AlexNet.png" width="500" height="200">

### Contribution

ImageNet LSVRC 경연 대회는 120만개의 고해상도 이미지를 1000개의 다른 class로 분류해주어야합니다. 이와같은 수백만개의 이미지에서 수천가지의 class를 학습하기 위해서는 학습 능력이 큰 모델이 필요합니다. CNN은 깊이와 폭을 다양하게 조절할 수 있으며 이미지의 성격에 대하여 강력하고 알맞은 분류를 할 수 있습니다. 하지만 이러한 장점에도 이전에는 엄청난 비용이 소모되었기 때문에 사용하기가 힘들었습니다. 2D convolution의 고도로 최적화 된 구현과 결합된 현재 GPU는 대규모 CNN의 교육을 용이하게 해주었습니다.

AlexNet은 5개의 convolution layers와 3개의 Fully-connected layers로 구성되어있습니다. 또한 성능 향상과 training 시간을 향상시키기 위한 여러가지 기능(ReLU,LRN,Data augmentation,Dropout)을 포함하였습니다.

이때의 GPU는 성능이 부족하였기 때문에 AlexNet은 2개의 GPU를 기반으로 한 병렬 구조입니다.

----
###Architexture
그림을 보고 그 구조를 파악하고, 파라미터의 개수를 알아 낼 수 있어야 합니다.    
 
[224 * 224 * 3] Input  

[55 * 55 * 96] Convolution layers1 : 96@ 11 * 11, stride=4, padding=0  
- parameter  11 * 11 * 3 * 48 * 2(병렬) : 34848  
[27 * 27 * 96] Max Pool1 : 3 * 3, stride=2  
[27 * 27 * 96] Normalization  

[27 * 27 * 256] Convolution layers2 : 256@ 5 * 5, stride=1, padding=2  
- parameter  5 * 5 * 48 * 128 * 2(병렬) : 307200  
[13 * 13 * 256] Max Pool2 : 3 * 3, stride=2  
[13 * 13 * 256] Normalization  

[13 * 13 * 384] Convolution layers3 : 384@ 3 * 3, stride=1, padding=1  
- parameter  3 * 3 * 256(윗단 아랫단이 합쳐짐) * 192 * 2(병렬) : 884736  

[13 * 13 * 384] Convolution layers4 : 384@ 3 * 3, stride=1, padding=1  
- parameter  3 * 3 * 192 * 192 * 2(병렬) : 663552  
 
[13 * 13 * 256] Convolution layers5 : 256@ 3 * 3, stride=1, padding=1  
- parameter  3 * 3 * 192 * 128 * 2(병렬) : 442368  
[6 * 6 * 256] Max Pool3 : 3 * 3, stride=2  

[4096] FC6  
[4096] FC7  
[1000] FC8
  
----
###Algorithm
#### ReLU
<img src="/images/ReLU.png" width="300" height="200">

지금은 기본적으로 사용하지만 tanh, sigmoid등을 사용할 시기였을 때, ReLU를 사용함으로써 학습 속도를 개선하였습니다.
ReLU는 0보다 작은 값은 0으로 사용하고, 0보다 큰 값은 해당 값을 그대로 사용하는 방법입니다. 

#### LRN(Local Response Normalization)
ReLU는 무제한의 활성화가 있기때문에 LRN이 필요합니다.
LRN은 output에서 convolution feature map이 나오면 그중에서 일정 부분만 높게 activation되게 해주는 작업입니다. AlexNet에서는 해당 작업을 수행해 주었다. 첨언하자면 지금은 성능상 큰 이점이 없어서 잘 사용하지 않습니다.

#### Regularization
-Data augmentation

AlexNet에서는 256 *
256의 original Image를 224 * 224의 Smaller Patch로 떠서 하나의 이미지 안에서 데이터를 32 * 32개를 늘릴 수 있고, 좌우 반전까지 하면 그의 *2배를 해주어 총 2048배의 데이터를 늘릴 수 있습니다.

-Dropout

Dropout은 Network의 일부를 생략하여 다른 Model을 학습한 것과 같은 효과를 얻어 overfitting을 개선하는 방법입니다. AlexNet에서는 test할 때 모든 뉴런을 사용하지만, output에 0.5를 곱해주었다. 이 방법은 처음이자 마지막으로 수행되었다고 합니다.

## ZFNet(2013)
<img src="/images/ZFNet.png" width="500" height="200">

ZFNet의 구조는 AlexNet에서 GPU를 하나만 쓰고 일부 convolution layer의 kernel 사이즈와 stride를 일부 조절해주었다.(layers1의 filter 사이즈를 11 * 11 -> 7 * 7, stride를 4 -> 1로 수정해주었고, 이에 따라 layers2의 stride를 1 -> 2로 수정하였다.)
ZFNet은 CNN을 가시화하여 CNN의 중간 과정을 눈으로 보고 개선 방향을 파악할 수 있는 방법을 만들었다.(Visualizing)

### Visualizing
CNN은 convolution계산 후 활성 함수를 통해 feature map을 생성하고, pooling하여 이미지를 축소 시키는 것을 반복하는데 이 과적을 반대로 해주어 원본 이미지에 mapping할 수 있는 이미지를 생성 할 수 있을 것이다.<img src="/images/ZFNet_1.png" width="250" height="350">

max-pooling은 이미지를 축소 시키는 과정에서 가장 강한 자극을 전달하는데 이 과정을 반대로하면 어느 부분이 강한 자극인지를 알 수 없는 문제가 생긴다. Visualizing은 가장 강한 자극의 위치를 가지고 있도록 하여 이와 같은 문제를 해결하였다.## VGG(2014)
stride는 모두 1, 제로패딩 1, 모든 convolution filter의 크기는 3 * 3 pooling은 2 * 2을 사용해주었다.

간단한 방법론으로 좋은 성적을 얻었다.

## GoogLeNet(2014)
<img src="/images/GoogLeNet.png" width="300" height="200">

Filter concatenation은 filter를 채널방향으로 더한 것을 의미한다. 

(b)그림은 (a)모델의 개선된 모델이다. 채널의 수를 중간에 한 번 줄였을 때 layers가 오히려 하나 더 쓰였는데 이 네트워크를 정의하는 파라미터의 수가 줄어든다. 이는 convolution의 파라미터를 정의하는 것은 input채널과 output채널이기 때문이다.

Receptive field : 출력단에 있는 하나의 픽셀이 입력 이미지의 얼마의 픽셀을 보고 이 정보가 취합되었는지를 의미한다.

Max-Pooling의 경우 1 * 1이 뒤에있는데 이는 출력 채널의 크기를 맞추기 위함이다. 

## ResNet(2015)
<img src="/images/GoogLeNet.png" width="100" height="300">

network가 deep 할 때 학습이 잘되는가를 생각해보면 아니라는 것을 알 수 있다. 이는 Vanishing/exploding gradients때문인데 이는 Better initialization methods/ batch normalization/ ReLU 과 같은 방법으로 해결할 수 있다.

Overfitting는 Training 에러는 줄어들고 Training acc는 늘어나는데 test acc가 계속 떨어질경우를 말한다. ResNet은 트레이닝도 잘되고 테스트도 잘되는데 성능이 잘 안나오는 경우인 Degradation을 해결하려하였다.

### Residual learning building block어떤 타겟과 현재 입력과의 차이만을 학습하게 해주는 방법이다. 입력과 출력의 차원이 같아야 한다는 단점을 갖고있다. 

1 * 1 conv를 이용하여 채널을 줄여주고 3 * 3 conv를 해주고 다시 1 * 1 conv를 해준다. 마지막에 다시 1 * 1 conv를 해주는 이유는 입력과 출력의 채널을 같게 해주어야하기 때문에 추가해준것이다. 만약 3 * 3 conv의 채널을  입력 채널과 같게해주면 바로 더해줄 수는 있어서 마지막의 1 * 1 conv가 필요없지만 파라미터의 수가 많아질 것이다.

ResNet의 한계는 Layers의 개수가 1000개를 넘어가면 여전히 잘 학습이 안되는 성능을 보인다는 것이다.

## Reference

[ImageNet Classification with Deep Convolutional
Neural Networks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)  [ReLU](http://pythonkim.tistory.com/40)  
[LRN](https://translate.google.co.kr/translate?hl=ko&sl=en&u=https://prateekvjoshi.com/2016/04/05/what-is-local-response-normalization-in-convolutional-neural-networks/&prev=search)   
[최신논문으로 시작하는 딥러닝_최성준](http://m.edwith.org/deeplearningchoi)  

